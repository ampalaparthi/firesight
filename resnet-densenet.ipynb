{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1887ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting datasets[vision]\n",
      "  Using cached datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (2022.1.0)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (4.64.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.70.12.2)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (1.1.5)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (3.7.4.post0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (20.9)\n",
      "Requirement already satisfied: responses<0.19 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.17.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (4.5.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (6.0.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.3.4)\n",
      "Requirement already satisfied: Pillow>=6.2.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (8.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (3.10.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->datasets[vision]) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (1.26.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (2021.5.30)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from responses<0.19->datasets[vision]) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tqdm>=4.62.1->datasets[vision]) (5.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (1.6.3)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->datasets[vision]) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets[vision]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets[vision]) (2021.1)\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-2.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets[vision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb682a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f6c0fbdc8e47168c834ad4a9230bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/39375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6053146b694684a1a0be0970ef9c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/8617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-320a3a01cff974fc\n",
      "Reusing dataset image_folder (/home/ubuntu/.cache/huggingface/datasets/image_folder/default-320a3a01cff974fc/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709bc90f070d4f8999dafeee812b94ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_folder = \"../train-val/Training/\"\n",
    "test_folder = \"../test/Test/\"\n",
    "import torch.utils.data as data\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"imagefolder\", ignore_verifications=True, data_files={\"train\": f\"{train_folder}**\", \"test\": f\"{test_folder}**\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a6fdaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 31500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 7875\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 8617\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "train_valid = ds['train'].train_test_split(test_size=0.2)\n",
    "ds = datasets.DatasetDict({\n",
    "    'train': train_valid['train'],\n",
    "    'val': train_valid['test'],\n",
    "    'test': ds['test']\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a30f756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n",
      "Torchvision Version:  0.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b447c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "num_epochs = 15\n",
    "feature_extract = True\n",
    "data_dir = \"train-val/Training\"\n",
    "test_dir = \"test/Test\"\n",
    "percent_val = 0.1\n",
    "save_path = \"saved-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fc8b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10651bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a67f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fbdf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6069c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets = {}\n",
    "orig_set = datasets.ImageFolder(train_folder)\n",
    "n = len(orig_set)\n",
    "n_val = int(percent_val * n)\n",
    "train_dataset, val_dataset = random_split(orig_set, [n-n_val, n_val])\n",
    "val_dataset.dataset.transform = data_transforms[\"val\"]\n",
    "train_dataset.dataset.transform = data_transforms[\"train\"]\n",
    "image_datasets[\"val\"] = val_dataset\n",
    "image_datasets[\"train\"] = train_dataset\n",
    "image_datasets[\"test\"] = datasets.ImageFolder(test_folder, data_transforms[\"test\"])\n",
    "\n",
    "# Create training, validation, and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3bc326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53a4965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.9779\n",
      "val Loss: 0.0119 Acc: 0.9952\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9776\n",
      "val Loss: 0.0141 Acc: 0.9929\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.0620 Acc: 0.9775\n",
      "val Loss: 0.0117 Acc: 0.9967\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9783\n",
      "val Loss: 0.0151 Acc: 0.9936\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9773\n",
      "val Loss: 0.0116 Acc: 0.9964\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9780\n",
      "val Loss: 0.0118 Acc: 0.9957\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.9778\n",
      "val Loss: 0.0111 Acc: 0.9957\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0650 Acc: 0.9766\n",
      "val Loss: 0.0126 Acc: 0.9954\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9767\n",
      "val Loss: 0.0118 Acc: 0.9954\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9774\n",
      "val Loss: 0.0121 Acc: 0.9947\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 0.9756\n",
      "val Loss: 0.0200 Acc: 0.9903\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0646 Acc: 0.9770\n",
      "val Loss: 0.0129 Acc: 0.9939\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9777\n",
      "val Loss: 0.0108 Acc: 0.9954\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9803\n",
      "val Loss: 0.0131 Acc: 0.9957\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9799\n",
      "val Loss: 0.0165 Acc: 0.9939\n",
      "\n",
      "Training complete in 16m 52s\n",
      "Best val Acc: 0.996698\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "torch.save(model_ft.state_dict(), os.path.join(os.path.join(save_path, \"resnet\"), \"resnet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5429770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqpklEQVR4nO3deZxcVZn/8c833Z0ESEgIhhEIGEQIssYYAsiwiayyiMooIAMIMgyi4swwoIyK48y4jMrMIBLRAURBGVAW+QGiQkQ2IRGICSBECNCsASGQQJbufn5/nFPJ7Up1dXV3VYWkvu/Xq151l3NPPXXr3nruPXdTRGBmZq1r2OoOwMzMVi8nAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgQDICkkvSN3T5f0hVrKDuJzjpF082DjtLWDpL0lda7Gzz9C0lOSFkl6VwM/Z66kvetd9s1O0jmSfry644AWSwSSfinpXysMP1zSc5Laa60rIk6JiK/UIaaJOWms+OyIuCwi9h9q3VU+cwtJPZK+26jPWBvlFTckHVkY1p6HTVyNoTXKN4HTImJURNxXGihp85wcSq+QtLjQv8dAPiQitouIGfUuOxCSjpfUXfa9FknapN6f9WbUUokAuAQ4VpLKhh8LXBYRXc0PabX4W+Bl4KOSRjTzgyW1NfPzGuAvwL+uad9jIBs5BW8D5pYPjIgnc3IYFRGj8uCdCsN+N8TPXV3uKn6v/HpmdQfVDK2WCK4BxgErtlgkbQAcAlwqaZqkuyS9IulZSd+RNLxSRZIukfRvhf4z8jTPSPp4Wdn3S7pP0qt5V/ucwujb8vsreQtkt7x1cnth+vdIulfSwvz+nsK4GZK+IukOSa9JulnSW/qZD38L/AuwHDi0LNbDJd2fY/2zpAPz8HGSLs7f72VJ1+ThvWLNw4pNaJdIukDSDZIWA/v0Mz+Q9NeS7sy/w1P5M3aW9Hzxj0XShyTdX/7lJO2a9/DaCsOOkDQ7d0+TNDN//vOSvt3P/Cq6CVgGfKzSyPx7nFToL/8tQ9Kpkh7Nv9dXJG2Zl7tXJf1f+TIn6fOSXpQ0X9IxheEjJH1T0pP5e0yXtE4et7ekTklnSnoOuLhCrMMk/YukJyS9IOlSSWNyvYuANuABSX+udebk73uHpHMl/QU4J3+/WyS9lL/HZZLGFqaZL+l9ufucPA8uzfNnrqSpgyw7JS9nr0m6UtIVKqyzA5E/93OSHszL/8WSRhbGf0LSPEl/kXSdCnsSkraT9Ks87nlJny9UPbxK/GdKejqP+5OkfQcTe00ioqVewPeBHxT6/w64P3e/G9gVaAcmAg8BpxfKBvCO3H0J8G+5+0DgeWB7YD3g8rKyewM7kBLvjrnsB/K4iblse+Fzjgduz93jSFvvx+a4jsr9G+bxM4A/A1sD6+T+r1X5/nsAS4ENgPOA6wrjpgELgf1yrJsC2+Rx/w+4Ik/XAexVHmuV+bQQ2D3XObKf+bE58Fr+nh3AhsDkPO5B4KDC51wN/GMf3/PPwH6F/iuBs3L3XcCxuXsUsGuNy845wI+Bw4DHcnzt+ftOLPweJ1X6LQvz5jpgfWC7/Fv8Bng7MCZ/x+MKy00X8G1gBLAXsBiYlMf/V65rHDAa+AXw1bJpv56nXafC9/k4MC9/9ijg58CPKv2O/cyX4u99fP7cT+V5sw7wDtIyNQIYT9r4+a/C9POB9xXm8RLgYFIi+ipw90DLAsOBJ4DP5N/pg6QE/m99fIdev1OF8fOBOcBmeX7fwcr1/73Ai8CU/B3PA27L40YDzwL/SFr2RwO71BD/JOApYJPC/8SWDftfbFTFb9YX8NekP6Z1cv8dwGf7KHs6cHUfC/wlhQXhIgp/vqQ/5T5XItIKfG7hB66WCI4F7imb/i7g+Nw9A/iXwrhTgZuqfP8fANfk7t1IewUb5f7vleIqm2ZjoAfYoMK4VVagCvPp0n5+k+L8+FxxnpeVO5PUhEdeGV8HNu6j7L8BF+Xu0aQ/0Lfl/tuALwNvGeCycw7w49z9e+DvGVwi2L3QPws4s9D/LfKfJCv/zNcrjP8/4AuA8nfasjBuN+DxwrTLgJFVvs9vgFML/ZPy8tBe/jv2M1/KE8GT/ZT/AHBfoX8+vf/cf10Yty3wxkDLAnsCTwMqjL+d6omgC3il8Ppz2eeeUug/uDQe+F/gG4Vxo/J8nEjaoLmvj8+sFv87gBeA9wEdA1lOB/NqtaYhIuJ2YAFwuKS3AzuTtuCRtLWk63OzwqvAfwD9NbMAbELK3iVPFEdK2kXSrZIWSFoInFJjvaW6nygb9gRpa73kuUL366QFcRW52eBI4DKAiLgLeBI4OhfZjLQlXW4z4C8R8XKNMZcrzpv+5kdfMUDaGj9U0ijgb4DfRcSzfZS9HPig0jGQDwJ/iIjSfDyRlKwfVmpqO2QQ3+lfgLNJW3kD9Xyh+40K/cXf7+WIWFzof4K0TIwH1gVmKTWhvUJqthpfKLsgIpZUiaN82XqClNj+qsbv0Zfy33sjST/NzRyvkn7Hast/+fI8Un0fa+ir7CbA05H/VSvFVcHdETG28NqybHz5Ol5q/uk1HyNiEfASaR2ttjz3GX9EzCNtiJ4DvJDnX8MOXLdcIsguJbWTHwvcHBGlFfEC4GFgq4hYH/g8acurP8+SfvCSzcvGX07ahd8sIsYA0wv1BtU9QzpoV7Q5aWtnoI4gNUl8Nye750gL69/m8U8B5Qt/afi4YrtuwWLSHxIAkt5aoUz5d6w2P/qKgYh4mrQ3dATpt/tRpXK57IOklfMgUqK7vDDu0Yg4CtiI1HRylaT1+qqrj/p/RWpWObVsVK/5AVSaHwOxQVlsm5OWiRdJSWO7wh/XmFh58BYGvmxtTtoqfr5y8ZqVf+5X87Ad83r1MWpbr4biWWBTqdeJIZv1VbhG5et46UByr/mYf68NSeton8tzfyLi8oj461x3kJbVhmjlRPA+4BPADwvDRwOvAoskbUPa9a/F/wHHS9pW0rrAl8rGjyZtUS+RNI2VW+CQ9k56SO20ldwAbC3paKVTFT9C2oW8vsbYio4jNWPtAEzOr92ByZJ2IO3iniBp33wgcVNJ2+St7htJCWQDSR2S9sx1PgBsJ2lyPnh2Tg1xVJsflwHvk/Q3+ftuKGlyYfylwD/n73B1P59zOfBpUjPBlaWBkj4maXxE9JCaAAC6a4i73Nk5lqL7SXsi6yodMD9xEPWW+7Kk4UqnZR4CXJlj/z5wrqSNAPLvdcAA6v0J8Fml04lHkfaAr4j6nz03GlhEOiFiU+CMOtdfyV2k3/S0vBwdTjoGNhSflDRB0jjSRuIVefjlpPVmct4D/Q/g9xExn7SevlXS6UoH4UdL2qW/D5I0SdJ7c31LSEl/MMtoTVoyEeQf6E7Sgd3rCqP+ifSn9BppJbtilYkr13cjqZ37FtJW4i1lRU4lnXL4GvBFUuIoTfs68O/AHXkXf9eyul8irfz/SNrd/GfgkIh4sZbYSvIKuC+p/fm5wmsWqUnhuIi4BzgBOJd0HOW3rNzSOZbU7vkwqe3y9BzfI8C/Ar8GHiW1w/an2vx4ktT++o+kUzXvB3YqTHt1junqsiaTSn5Caiu/pWx+HQjMVToz5r+Bj5aaUDSA8+Aj4g7gnrLB55La5p8nbWRcVktdVTxHOjngmVzXKRHxcB53Jml5uzs3ufya1M5fq4tIe1W3AY+T/nA+NcR4K/ky6UDqQtJJBz9vwGf0EhHLSE2CJ5KS/cdIf8pLq0y2m1a9jmDnwvjLgZtJJwo8RjoORUT8hnTc5mekPZEtgY/mca+RDpQfSvotHwX2qeErjAC+Rtrze4609/r5qlMMgXo3oZm9+Smdzvh3EfHr1R2LrTkk/R6YHhEXD2La+aSTANbKZa4l9whszSXpQ6T20vK9LrNeJO0l6a25aeg40qnKN63uuN6MGpYIJF2kdJHKnD7GS9L/KF2EMVvSlEbFYmsHSTNIB/Q/mdvIzaqZRDqGtZDU1PjhKmeZtbSGNQ3lg4mLSOeQb19h/MGk9siDgV2A/46Ifg+imJlZfTVsjyAibiMd7OvL4aQkERFxNzBW0saNisfMzCpbnTeE2pTeF2h05mGr7LpJOhk4GWC99dZ79zbbbDPgD1ve3cPiZd0MAyQQSu+9uoVK4yt0D0RPBD0BPT1BRKk/DYvSuDxs5fje4wCGaWWcwwpxDiu907tfInWj3uW08ruQ648cZ6y4whyCUhw5FlaOW1G2fBipPHl+rfjdCh2lOaiykcX5Wjzlu/e0q0+vqFVpXBPjWGXeqtf8WXWeqcq0peUiLRvDhuX3Ve7HuPoVl7PUHyuWt9KyF6QFM/LQlctp734qli98VsUAVnYMpP0kzffC/0hp/c0ji/3KA1f2r/ztiv9Bpf+DwZg1a9aLETG+0rjVmQgqfZ3Kv0PEhcCFAFOnTo2ZM2cO+MOun/0Mp11+34CnK+poEx1tw1a8hreJjva0U/XGsm7eWN7N0uU9LOseWPO1SDcaGdXRxjrD21ino40RHanepct7WNrVw9KubpZ29bCsa2XdQQNPLK4Sa2nhHN42jBHtwxje3kZHmyoktJVJrTwZUt7/JlUttDdx2EOyTkcb6w5Py2J6b2fdsmHrDm9P3R2lYe0rxkcES5b3sGR5d3p1pe7S+rFi+PIelnQVupenZbx8/Jp6YmOUvdfD3+31dj530DsHNa2k8jsUrLA6E0Enva/Um8DKK/Xqbu9JG/Hrf9iT5d3B8u4elnf3sKxrZXd6FcZ1B8u7Ko9b3h0s6+5ZMT5IK8/Iwh/5yI5hvYaNbM/vHYXxK8q2MaJ9WK8t4r5EpM9e2tWTk0Q3y7pKyaKHpXllKiWNUgIpDV/W1UNbm9KfeEcbI9qGMbw9v3L3iPaVw0a0D2N4W0pMwwtl24eppnhrVW0vqVGi11ZmqWPldl/vrchYdYsyly+9NeoPK+i9R1a+91ht3vXke8mU9k5L5QNY1tXD68u6eX1ZF28s787d3byxrCu/d7O40P3swuW53MphXQP4gdIyN6zXOjCyI60bo0e2M370iDwuD+9oY2R7Xk7zctc2TLQPE23DhtE2DNqGDcv9Kryncm3lw9sK00q0tYk2FbbSoffea2FHsHwLPXWvnLBYhyR6IujuDpb39NDdE3Tl/4/unmB5d6T3nlL/yjJdPUFXd0967+lZUbY0bPtNxwxhSerb6kwE15Gu+vsp6WDxwkYe0R81op13bDS6UdU3jSRGtLcxor1tcHe5eZOSRJugbbU2BNlALevq4Y1l3by+fGVykCj82ac//BHtbbQN82/7ZtWwRCCpdFXnW5Qet/cl0u1giYjppFsnHEy6MvJ10hWtZrYGKe0hjkmrtq2hGpYI8k29qo0P4JON+nwze/Navnw5nZ2dLFlS7eaoNhgjR45kwoQJdHTUnpzXpMfImdlaorOzk9GjRzNx4sS6HmtqdRHBSy+9RGdnJ1tssUXN0/kWE2bWdEuWLGHDDTd0EqgzSWy44YYD3tNyIjCz1cJJoDEGM1+dCMzMWpwTgZm1pLa2NiZPnsz222/PkUceyeuvv17ztPPnz+fyyy/vv2AF73nPewY1XaUYtt9+ldu4DYoTgZm1pHXWWYf777+fOXPmMHz4cKZPn95rfHd339ftV0sEXV3VH/B25513DjzYBnMiMLOWt8ceezBv3jxmzJjBPvvsw9FHH80OO+xAd3c3Z5xxBjvvvDM77rgj3/ve9wA466yz+N3vfsfkyZM599xzueSSSzjyyCM59NBD2X///Vm0aBH77rsvU6ZMYYcdduDaa69d8VmjRqXHSs+YMYO9996bD3/4w2yzzTYcc8wxlO4GPWvWLPbaay/e/e53c8ABB/Dss8+uGL7TTjux2267cf7559ft+/v0UTNbrb78i7k8+Myrda1z203W50uHbldT2a6uLm688UYOPPBAAO655x7mzJnDFltswYUXXsiYMWO49957Wbp0Kbvvvjv7778/X/va1/jmN7/J9denR4dfcskl3HXXXcyePZtx48bR1dXF1Vdfzfrrr8+LL77IrrvuymGHHbbKgdz77ruPuXPnsskmm7D77rtzxx13sMsuu/CpT32Ka6+9lvHjx3PFFVdw9tlnc9FFF3HCCSdw3nnnsddee3HGGfV79LMTgZm1pDfeeIPJkycDaY/gxBNP5M4772TatGkrzsG/+eabmT17NldddRUACxcu5NFHH2X48OGr1Lfffvsxbtw4IJ3P//nPf57bbruNYcOG8fTTT/P888/z1re+tdc006ZNY8KECQBMnjyZ+fPnM3bsWObMmcN+++0HpCaqjTfemIULF/LKK6+w1157AXDsscdy44031mVeOBGY2WpV65Z7vZWOEZRbb731VnRHBOeddx4HHHBArzIzZsyoOt1ll13GggULmDVrFh0dHUycOLHiuf0jRoxY0d3W1kZXVxcRwXbbbcddd93Vq+wrr7zSsFNufYzAzKwPBxxwABdccAHLly8H4JFHHmHx4sWMHj2a1157rc/pFi5cyEYbbURHRwe33norTzzR5x2gVzFp0iQWLFiwIhEsX76cuXPnMnbsWMaMGcPtt98OpGRTL94jMDPrw0knncT8+fOZMmUKEcH48eO55ppr2HHHHWlvb2ennXbi+OOPZ4MNNug13THHHMOhhx7K1KlTmTx5MgN5mNbw4cO56qqr+PSnP83ChQvp6uri9NNPZ7vttuPiiy/m4x//OOuuu+4qeylD0bBnFjfKYB9MY2ZvHg899BDvfOfgHrBi/as0fyXNioiplcq7acjMrMU5EZiZtTgnAjNbLda0Zuk1xWDmqxOBmTXdyJEjeemll5wM6qz0PIKRIwf2HFufNWRmTTdhwgQ6OztZsGDB6g5lrVN6QtlAOBGYWdN1dHQM6Ala1lhuGjIza3FOBGZmLc6JwMysxTkRmJm1OCcCM7MW50RgZtbinAjMzFqcE4GZWYtzIjAza3FOBGZmLc6JwMysxTkRmJm1OCcCM7MW50RgZtbinAjMzFqcE4GZWYtraCKQdKCkP0maJ+msCuPHSPqFpAckzZV0QiPjMTOzVTUsEUhqA84HDgK2BY6StG1ZsU8CD0bETsDewLckDW9UTGZmtqpG7hFMA+ZFxGMRsQz4KXB4WZkARksSMAr4C9DVwJjMzKxMIxPBpsBThf7OPKzoO8A7gWeAPwKfiYie8ooknSxppqSZfti1mVl9NTIRqMKwKOs/ALgf2ASYDHxH0vqrTBRxYURMjYip48ePr3ecZmYtrZGJoBPYrNA/gbTlX3QC8PNI5gGPA9s0MCYzMyvTyERwL7CVpC3yAeCPAteVlXkS2BdA0l8Bk4DHGhiTmZmVaW9UxRHRJek04JdAG3BRRMyVdEoePx34CnCJpD+SmpLOjIgXGxWTmZmtqmGJACAibgBuKBs2vdD9DLB/I2MwM7PqfGWxmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgRmZi2u30QgaVwzAjEzs9Wjlj2C30u6UtLB+ZGSZma2FqklEWwNXAgcC8yT9B+Stm5sWGZm1iz9JoL89LBfRcRRwEnAccA9kn4rabeGR2hmZg3V7/MIJG0IfIy0R/A88CnSk8YmA1cCWzQwPjMza7BaHkxzF/Aj4AMR0VkYPlPS9D6mMTOzNUQtiWBSRESlERHx9TrHY2ZmTVbLweKbJY0t9UjaQNIvGxeSmZk1Uy2JYHxEvFLqiYiXgY0aFpGZmTVVLYmgW9LmpR5JbwMqNhWZmdmap5ZjBGcDt0v6be7fEzi5cSGZmVkz9ZsIIuImSVOAXQEBn42IFxsemZmZNUUtewQA3cALwEhgW0lExG2NC8vMzJqllgvKTgI+A0wA7iftGdwFvLehkZmZWVPUcrD4M8DOwBMRsQ/wLmBBQ6MyM7OmqSURLImIJQCSRkTEw8CkxoZlZmbNUssxgs58Qdk1wK8kvQw808igzMyseWo5a+iI3HmOpFuBMcBNDY3KzMyapmoikDQMmB0R2wNExG+rlTczszVP1WMEEdEDPFC8stjMzNYutRwj2BiYK+keYHFpYEQc1rCozMysaWpJBF9ueBRmZrba1HKw2McFzMzWYv1eRyDpNUmv5tcSSd2SXq2lckkHSvqTpHmSzuqjzN6S7pc0t3BjOzMza5Ja9ghGF/slfQCY1t90ktqA84H9gE7gXknXRcSDhTJjge8CB0bEk5L8nAMzsyar5criXiLiGmq7z9A0YF5EPBYRy4CfAoeXlTka+HlEPJnrfmGg8ZiZ2dDUctO5DxZ6hwFTqe3BNJsCTxX6O4FdyspsDXRImgGMBv47Ii6tEMPJ5GcgbL65z2Q1M6unWs4aOrTQ3QXMZ9Ut+0pUYVh5AmkH3g3sC6wD3CXp7oh4pNdEERcCFwJMnTrVT0czM6ujWo4RnDDIujuBzQr9E1j1HkWdwIsRsRhYLOk2YCfgEczMrClqOWvoh/mgbql/A0kX1VD3vcBWkraQNBz4KHBdWZlrgT0ktUtal9R09FDN0ZuZ2ZDV0jS0Y0S8UuqJiJclvau/iSKiS9JpwC+BNuCiiJgr6ZQ8fnpEPCTpJmA20AP8ICLmDOaLmJnZ4NSSCIZJ2iAiXgaQNK7G6YiIG4AbyoZNL+v/T+A/awvXzMzqrZY/9G8Bd0q6inSw92+Af29oVGZm1jS1HCy+VNJM0rUDAj5YvCjMzMzWbLVcR7ArMDcivpP7R0vaJSJ+3/DozMys4Wq5svgCYFGhf3EeZmZma4FaEoEiYsVFXPlhNTUdLDYzsze/WhLBY5I+Lakjvz4DPNbowMzMrDlqSQSnAO8Bnmbl/YI+0cigzMyseWo5a+gF0lXBAEhaBzgEuLKBcZmZWZPUdBtqSW2SDpJ0KfA48JHGhmVmZs1SdY9A0p6kZwa8H7gH2B14e0S83oTYzMysCfpMBJI6gSdJp4qeERGvSXrcScDMbO1SrWnoZ6SHy3wEOFTSetT2QBozM1uD9JkIIuIzwETg28A+pGcEjJf0N5JGNSc8MzNrtKoHiyO5JSI+QUoKRwMfID2lzMzM1gI1XyEcEcuBXwC/yKeQmpnZWqCm00fLRcQb9Q7EzMxWj0ElAjMzW3s4EZiZtbhankewNXAG8LZi+Yh4bwPjMjOzJqnlYPGVwHTg+0B3Y8MxM7NmqyURdEWEH0RjZraWquUYwS8knSppY0njSq+GR2ZmZk1Ryx7Bcfn9jMKwAN5e/3DMzKzZankewRbNCMTMzFaPWs4a6gD+HtgzD5oBfC9faWxmZmu4WpqGLgA6gO/m/mPzsJMaFZSZmTVPLYlg54jYqdB/i6QHGhWQmZk1Vy1nDXVL2rLUI+nt+HoCM7O1Ri17BGcAt0p6DBDpCuMTGhqVmZk1TS1nDf1G0lbAJFIieDgiljY8MjMza4pqzyx+b0TcIumDZaO2lERE/LzBsZmZWRNU2yPYC7gFOLTCuACcCMzM1gJ9JoKI+FLu/NeIeLw4TpIvMjMzW0vUctbQzyoMu6regZiZ2epR7RjBNsB2wJiy4wTrAyMbHZiZmTVHtT2CScAhwFjScYLSawrwiVoql3SgpD9JmifprCrldpbULenDNUduZmZ1Ue0YwbXAtZJ2i4i7BlqxpDbgfGA/oBO4V9J1EfFghXJfB3450M8wM7Ohq+WCsvskfZLUTLSiSSgiPt7PdNOAeRHxGICknwKHAw+WlfsU6TjEzrUGbWZm9VPLweIfAW8FDgB+C0wAXqthuk2Bpwr9nXnYCpI2BY4gPQqzT5JOljRT0swFCxbU8NFmZlarWhLBOyLiC8DiiPgh8H5ghxqmU4VhUdb/X8CZEVH13kURcWFETI2IqePHj6/ho83MrFa1NA2VnjvwiqTtgeeAiTVM1wlsVuifADxTVmYq8FNJAG8BDpbUFRHX1FC/mZnVQS2J4EJJGwBfAK4DRgFfrGG6e4Gt8sVnTwMfBY4uFig+/UzSJcD1TgJmZs1Vy03nfpA7f8sAnlMcEV2STiOdDdQGXBQRcyWdksdXPS5gZmbNUe2Csn+oNmFEfLu/yiPiBuCGsmEVE0BEHN9ffWZmVn/V9ghG5/dJpFM7r8v9hwK3NTIoMzNrnmoXlH0ZQNLNwJSIeC33nwNc2ZTozMys4Wo5fXRzYFmhfxm1nTVkZmZrgFrOGvoRcI+kq0nXARwBXNrQqMzMrGlqOWvo3yXdCOyRB50QEfc1NiwzM2uWamcNrR8Rr0oaB8zPr9K4cRHxl8aHZ2ZmjVZtj+By0m2oZ9H71hDK/TVfU2BmZm9e1c4aOiS/+7GUZmZrsWpNQ1OqTRgRf6h/OGZm1mzVmoa+VWVcAO+tcyxmZrYaVGsa2qeZgZiZ2epRy3UE5NtPb0vvJ5T5WgIzs7VAv4lA0peAvUmJ4AbgIOB2fFGZmdlaoZZbTHwY2Bd4LiJOAHYCRjQ0KjMza5paEsEbEdEDdElaH3gBX0NgZrbWqOUYwUxJY4Hvky4uWwTc08igzMyseapdR/Ad4PKIODUPmi7pJmD9iJjdlOjMzKzhqu0RPAp8S9LGwBXATyLi/qZEZWZmTdPnMYKI+O+I2A3YC/gLcLGkhyR9UdLWTYvQzMwaqt+DxRHxRER8PSLeBRxNeh7BQw2PzMzMmqLfRCCpQ9Khki4DbgQeAT7U8MjMzKwpqh0s3g84Cng/6SyhnwInR8TiJsVmZmZNUO1g8edJzyT4Jz+Exsxs7eWbzpmZtbhariw2M7O1mBOBmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLa2gikHSgpD9JmifprArjj5E0O7/ulLRTI+MxM7NVNSwRSGoDzgcOArYFjpK0bVmxx4G9ImJH4CvAhY2Kx8zMKmvkHsE0YF5EPBYRy0i3sT68WCAi7oyIl3Pv3cCEBsZjZmYVNDIRbAo8VejvzMP6ciLpwTerkHSypJmSZi5YsKCOIZqZWSMTgSoMi4oFpX1IieDMSuMj4sKImBoRU8ePH1/HEM3MrNqDaYaqE9is0D8BeKa8kKQdgR8AB0XESw2Mx8zMKmjkHsG9wFaStpA0HPgocF2xgKTNgZ8Dx0bEIw2MxczM+tCwPYKI6JJ0GvBLoA24KCLmSjolj58OfBHYEPiuJICuiJjaqJjMzGxViqjYbP+mNXXq1Jg5c+bqDsPMbI0iaVZfG9q+stjMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2txTgRmZi3OicDMrMU5EZiZtTgnAjOzFtfQRCDpQEl/kjRP0lkVxkvS/+TxsyVNaWQ8Zma2qoYlAkltwPnAQcC2wFGSti0rdhCwVX6dDFzQqHjMzKyyRu4RTAPmRcRjEbEM+ClweFmZw4FLI7kbGCtp4wbGZGZmZdobWPemwFOF/k5glxrKbAo8Wywk6WTSHgPAIkl/GmRMbwFeHOS0rrf5dbrextXpehtX55u13rf1NaKRiUAVhsUgyhARFwIXDjkgaWZETB1qPa63OXW63sbV6XobV+eaWG8jm4Y6gc0K/ROAZwZRxszMGqiRieBeYCtJW0gaDnwUuK6szHXA3+azh3YFFkbEs+UVmZlZ4zSsaSgiuiSdBvwSaAMuioi5kk7J46cDNwAHA/OA14ETGhVPNuTmJdfb1Dpdb+PqdL2Nq3ONq1cRqzTJm5lZC/GVxWZmLc6JwMysxbVEIpB0kaQXJM2pc72bSbpV0kOS5kr6TB3qHCnpHkkP5Dq/XI9YC/W3SbpP0vV1rHO+pD9Kul/SzDrWO1bSVZIezvN4tyHWNynHWHq9Kun0OsX62fx7zZH0E0kj61TvZ3Kdc4cSa6V1QNI4Sb+S9Gh+36BO9R6Z4+2RNOBTHfuo8z/zcjBb0tWSxtap3q/kOu+XdLOkTepRb2HcP0kKSW+pU7znSHq6sAwfPNB6K4qItf4F7AlMAebUud6NgSm5ezTwCLDtEOsUMCp3dwC/B3atY8z/AFwOXF/HOucDb2nA7/ZD4KTcPRwYW8e624DngLfVoa5NgceBdXL//wHH16He7YE5wLqkEzt+DWw1yLpWWQeAbwBn5e6zgK/Xqd53ApOAGcDUOtW5P9Ceu79ex1jXL3R/Gphej3rz8M1IJ8s8MZj1o494zwH+aajLVvmrJfYIIuI24C8NqPfZiPhD7n4NeIj0pzCUOiMiFuXejvyqyxF9SROA9wM/qEd9jSRpfdKK8L8AEbEsIl6p40fsC/w5Ip6oU33twDqS2kl/3PW4HuadwN0R8XpEdAG/BY4YTEV9rAOHk5It+f0D9ag3Ih6KiMFe/d9XnTfneQBwN+mao3rU+2qhdz0Gsa5V+X85F/jnwdTZT7111xKJoBkkTQTeRdqCH2pdbZLuB14AfhURQ64z+y/SgtlTp/pKArhZ0qx8O5B6eDuwALg4N2X9QNJ6daob0nUtP6lHRRHxNPBN4EnS7VEWRsTNdah6DrCnpA0lrUs61XqzfqYZiL+KfN1Oft+ojnU30seBG+tVmaR/l/QUcAzwxTrVeRjwdEQ8UI/6ypyWm7MuGkxzXiVOBHUgaRTwM+D0si2MQYmI7oiYTNrqmSZp+6HWKekQ4IWImDXUuirYPSKmkO4m+0lJe9ahznbSbvEFEfEuYDGp+WLI8gWOhwFX1qm+DUhb11sAmwDrSfrYUOuNiIdIzSC/Am4CHgC6qk60lpN0NmkeXFavOiPi7IjYLNd52lDry0n7bOqUVMpcAGwJTCZtdHyrHpU6EQyRpA5SErgsIn5ez7pzU8gM4MA6VLc7cJik+aQ7wb5X0o/rUC8R8Ux+fwG4mnTn2aHqBDoLe0NXkRJDPRwE/CEinq9Tfe8DHo+IBRGxHPg58J56VBwR/xsRUyJiT1IzwaP1qDd7Xvluv/n9hTrWXXeSjgMOAY6J3GBeZ5cDH6pDPVuSNgoeyOvbBOAPkt461Ioj4vm8odgDfJ/6rGtOBEMhSaQ27Ici4tt1qnN86YwISeuQ/mQeHmq9EfG5iJgQERNJzSK3RMSQt1olrSdpdKmbdFBvyGdnRcRzwFOSJuVB+wIPDrXe7Cjq1CyUPQnsKmndvEzsSzpeNGSSNsrvmwMfpL5xXwccl7uPA66tY911JelA4EzgsIh4vY71blXoPYz6rGt/jIiNImJiXt86SSeVPDfUutX7Nv1HUId1DWiZs4Z+QtqNWk76UU6sU71/TWofnw3cn18HD7HOHYH7cp1zgC82YH7sTZ3OGiK15T+QX3OBs+sY52RgZp4X1wAb1KHOdYGXgDF1nqdfJv2JzAF+BIyoU72/IyXAB4B9h1DPKusAsCHwG9Jexm+AcXWq94jcvRR4HvhlHeqcR7plfWk9G8zZPZXq/Vn+zWYDvwA2rUe9ZePnM7izhirF+yPgjzne64CN67Gc+RYTZmYtzk1DZmYtzonAzKzFORGYmbU4JwIzsxbnRGBm1uKcCGyNkm+3ULrz4nNld2Ic3s+0UyX9Tw2fcWedYt1b0sKyO56+rx515/qPl/SdetVnrathj6o0a4SIeIl0fQGSzgEWRcQ3S+MltcfKm5OVTzuTdF1Cf59Rl6uCs99FxCF1rM+s7rxHYGs8SZdI+rakW4GvS5om6c58s7o7S1cn5y3063P3OfmmXTMkPSbp04X6FhXKz9DKZyJclq8cRtLBedjtkv5HA3i+g6SJedof5puHXZXvT4OkfXPcf8zxjcjDd87f5QGl51WMztVtIukmpWcKfCOXbcvzZE6u57NDn8u2NvMega0ttgbeFxHdyrewjoiu3BTzH1S+h8w2wD6kZ0n8SdIFke4VVPQuYDvSbaXvAHZXevjO9/JnPC6p2m0f9lC6k2zJh4Bu0v36T4yIOyRdBJyam3kuIV1B/IikS4G/l/Rd4ArgIxFxb/5+b+T6JucYl+bvcB7pLqKbRsT2kB7wUyU+M+8R2Frjyojozt1jgCuVnux0LumPvJL/FxFLI+JF0g3X/qpCmXsiojPSTb7uByaSEshjEfF4LlMtEfwuIiYXXn/Ow5+KiDty949JtyuZRLp53SN5+A9Jz2SYBDwbEfdCuod+ofnrNxGxMCKWkG5F8TbgMeDtks7L9+gZ8h1xbe3mRGBri8WF7q8At+Yt4kOBvh4bubTQ3U3lPeRKZTSEOEvK7+0SVepVhfIlq8QXES8DO5HuXPtJ1oAHEdnq5URga6MxwNO5+/gG1P8waYt7Yu7/yCDq2Fwrn8F8FHB7rneipHfk4ceSnkr2MOlYwM4AkkYrPQmtIqXn4w6LiJ8BX6B+t++2tZQTga2NvgF8VdIdpGcT11VEvAGcCtwk6XbSHTYX9lF8j7LTRz+chz8EHCdpNjCO9ACeJcAJpGatP5KeJDc9IpaRks15kh4gPaimr70cSI9LnZGPTVwCfG4IX9dagO8+ajYIkkZFxKJ8FtH5wKMRcW6N004k3QZ8yE+eM6sH7xGYDc4n8hb3XFJT1PdWbzhmg+c9AjOzFuc9AjOzFudEYGbW4pwIzMxanBOBmVmLcyIwM2tx/x9Rh6dvL1ZuRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "ohist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f43e63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy on test set\n",
    "def test_accuracy(loader, model, is_val):\n",
    "    if is_val:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecf7dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 3924 / 3937 correct (99.67)\n",
      "Checking accuracy on test set\n",
      "Got 6431 / 8617 correct (74.63)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(dataloaders_dict[\"val\"], model_ft, True)\n",
    "test_accuracy(dataloaders_dict[\"test\"], model_ft, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98c1a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize densenet model\n",
    "# Initialize the model for this run\n",
    "model_name = \"densenet\"\n",
    "model_ft_densenet, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53dd9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft_densenet = model_ft_densenet.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft_densenet.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft_densenet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft_densenet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec00e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.1093 Acc: 0.9602\n",
      "val Loss: 0.0205 Acc: 0.9929\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0684 Acc: 0.9757\n",
      "val Loss: 0.0156 Acc: 0.9939\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.9766\n",
      "val Loss: 0.0271 Acc: 0.9911\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.0649 Acc: 0.9769\n",
      "val Loss: 0.0180 Acc: 0.9939\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9777\n",
      "val Loss: 0.0171 Acc: 0.9944\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.0605 Acc: 0.9780\n",
      "val Loss: 0.0144 Acc: 0.9949\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9780\n",
      "val Loss: 0.0118 Acc: 0.9952\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.9809\n",
      "val Loss: 0.0113 Acc: 0.9952\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0596 Acc: 0.9788\n",
      "val Loss: 0.0138 Acc: 0.9952\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0535 Acc: 0.9820\n",
      "val Loss: 0.0105 Acc: 0.9962\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0564 Acc: 0.9803\n",
      "val Loss: 0.0109 Acc: 0.9959\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0553 Acc: 0.9807\n",
      "val Loss: 0.0138 Acc: 0.9949\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9816\n",
      "val Loss: 0.0110 Acc: 0.9964\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0528 Acc: 0.9813\n",
      "val Loss: 0.0109 Acc: 0.9952\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0547 Acc: 0.9813\n",
      "val Loss: 0.0138 Acc: 0.9949\n",
      "\n",
      "Training complete in 37m 0s\n",
      "Best val Acc: 0.996444\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft_densenet, hist_densenet = train_model(model_ft_densenet, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "torch.save(model_ft.state_dict(), os.path.join(os.path.join(save_path, \"densenet\"), \"densenet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cec8eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "ohist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist_densenet]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d24ba999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 3923 / 3937 correct (99.64)\n",
      "Checking accuracy on test set\n",
      "Got 6186 / 8617 correct (71.79)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(dataloaders_dict[\"val\"], model_ft_densenet, True)\n",
    "test_accuracy(dataloaders_dict[\"test\"], model_ft_densenet, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872b64f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
