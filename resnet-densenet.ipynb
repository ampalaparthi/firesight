{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1887ed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting datasets[vision]\n",
      "  Using cached datasets-2.2.2-py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (2022.1.0)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (4.64.0)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.70.12.2)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (1.1.5)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (3.7.4.post0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (20.9)\n",
      "Requirement already satisfied: responses<0.19 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.17.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (4.5.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (6.0.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (2.25.1)\n",
      "Requirement already satisfied: dill<0.3.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (0.3.4)\n",
      "Requirement already satisfied: Pillow>=6.2.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from datasets[vision]) (8.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (3.10.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets[vision]) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging->datasets[vision]) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (1.26.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests>=2.19.0->datasets[vision]) (2021.5.30)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from responses<0.19->datasets[vision]) (1.16.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tqdm>=4.62.1->datasets[vision]) (5.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (1.6.3)\n",
      "Requirement already satisfied: idna-ssl>=1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->datasets[vision]) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->datasets[vision]) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets[vision]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas->datasets[vision]) (2021.1)\n",
      "Installing collected packages: datasets\n",
      "Successfully installed datasets-2.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets[vision]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb682a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db092eb242b848d0a37a724631dda3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/39375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d6406054494c278306b765446a7355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/8617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-320a3a01cff974fc\n",
      "Reusing dataset image_folder (/home/ubuntu/.cache/huggingface/datasets/image_folder/default-320a3a01cff974fc/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0a2d3c0181470c9c15e37a14004978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_folder = \"../train-val/Training/\"\n",
    "test_folder = \"../test/Test/\"\n",
    "import torch.utils.data as data\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"imagefolder\", ignore_verifications=True, data_files={\"train\": f\"{train_folder}**\", \"test\": f\"{test_folder}**\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a6fdaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 31500\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 7875\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 8617\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "train_valid = ds['train'].train_test_split(test_size=0.2)\n",
    "ds = datasets.DatasetDict({\n",
    "    'train': train_valid['train'],\n",
    "    'val': train_valid['test'],\n",
    "    'test': ds['test']\n",
    "})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a30f756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n",
      "Torchvision Version:  0.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b447c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet\"\n",
    "num_classes = 2\n",
    "batch_size = 8\n",
    "num_epochs = 15\n",
    "feature_extract = True\n",
    "data_dir = \"train-val/Training\"\n",
    "test_dir = \"test/Test\"\n",
    "percent_val = 0.1\n",
    "save_path = \"saved-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fc8b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10651bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83a67f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fbdf52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test':transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec6069c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets = {}\n",
    "orig_set = datasets.ImageFolder(train_folder)\n",
    "n = len(orig_set)\n",
    "n_val = int(percent_val * n)\n",
    "train_dataset, val_dataset = random_split(orig_set, [n-n_val, n_val])\n",
    "val_dataset.dataset.transform = data_transforms[\"val\"]\n",
    "train_dataset.dataset.transform = data_transforms[\"train\"]\n",
    "image_datasets[\"val\"] = val_dataset\n",
    "image_datasets[\"train\"] = train_dataset\n",
    "image_datasets[\"test\"] = datasets.ImageFolder(test_folder, data_transforms[\"test\"])\n",
    "\n",
    "# Create training, validation, and test dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val', 'test']}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3bc326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53a4965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.9779\n",
      "val Loss: 0.0119 Acc: 0.9952\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0632 Acc: 0.9776\n",
      "val Loss: 0.0141 Acc: 0.9929\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.0620 Acc: 0.9775\n",
      "val Loss: 0.0117 Acc: 0.9967\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.0624 Acc: 0.9783\n",
      "val Loss: 0.0151 Acc: 0.9936\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9773\n",
      "val Loss: 0.0116 Acc: 0.9964\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9780\n",
      "val Loss: 0.0118 Acc: 0.9957\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.9778\n",
      "val Loss: 0.0111 Acc: 0.9957\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0650 Acc: 0.9766\n",
      "val Loss: 0.0126 Acc: 0.9954\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9767\n",
      "val Loss: 0.0118 Acc: 0.9954\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9774\n",
      "val Loss: 0.0121 Acc: 0.9947\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0709 Acc: 0.9756\n",
      "val Loss: 0.0200 Acc: 0.9903\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0646 Acc: 0.9770\n",
      "val Loss: 0.0129 Acc: 0.9939\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9777\n",
      "val Loss: 0.0108 Acc: 0.9954\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9803\n",
      "val Loss: 0.0131 Acc: 0.9957\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9799\n",
      "val Loss: 0.0165 Acc: 0.9939\n",
      "\n",
      "Training complete in 16m 52s\n",
      "Best val Acc: 0.996698\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "torch.save(model_ft.state_dict(), os.path.join(os.path.join(save_path, \"resnet\"), \"resnet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5429770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "ohist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f43e63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy on test set\n",
    "def test_accuracy(loader, model, is_val):\n",
    "    if is_val:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecf7dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 3924 / 3937 correct (99.67)\n",
      "Checking accuracy on test set\n",
      "Got 6431 / 8617 correct (74.63)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(dataloaders_dict[\"val\"], model_ft, True)\n",
    "test_accuracy(dataloaders_dict[\"test\"], model_ft, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98c1a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize densenet model\n",
    "# Initialize the model for this run\n",
    "model_name = \"densenet\"\n",
    "model_ft_densenet, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53dd9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft_densenet = model_ft_densenet.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft_densenet.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft_densenet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft_densenet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec00e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9608\n",
      "val Loss: 0.0202 Acc: 0.9929\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0741 Acc: 0.9730\n",
      "val Loss: 0.0267 Acc: 0.9911\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.0711 Acc: 0.9750\n",
      "val Loss: 0.0125 Acc: 0.9962\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.0621 Acc: 0.9777\n",
      "val Loss: 0.0126 Acc: 0.9964\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.9765\n",
      "val Loss: 0.0175 Acc: 0.9947\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.0583 Acc: 0.9800\n",
      "val Loss: 0.0099 Acc: 0.9970\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.0593 Acc: 0.9784\n",
      "val Loss: 0.0224 Acc: 0.9926\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.0644 Acc: 0.9765\n",
      "val Loss: 0.0104 Acc: 0.9975\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9794\n",
      "val Loss: 0.0133 Acc: 0.9959\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9793\n",
      "val Loss: 0.0164 Acc: 0.9947\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.0552 Acc: 0.9802\n",
      "val Loss: 0.0114 Acc: 0.9954\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0569 Acc: 0.9805\n",
      "val Loss: 0.0116 Acc: 0.9972\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0553 Acc: 0.9795\n",
      "val Loss: 0.0123 Acc: 0.9970\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9810\n",
      "val Loss: 0.0119 Acc: 0.9977\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0615 Acc: 0.9786\n",
      "val Loss: 0.0092 Acc: 0.9980\n",
      "\n",
      "Training complete in 48m 3s\n",
      "Best val Acc: 0.997968\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft_densenet, hist_densenet = train_model(model_ft_densenet, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "torch.save(model_ft_densenet.state_dict(), os.path.join(os.path.join(save_path, \"densenet\"), \"densenet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cec8eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method\n",
    "ohist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist_densenet]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d24ba999",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bfb08d63f6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft_densenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft_densenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "test_accuracy(dataloaders_dict[\"val\"], model_ft_densenet, True)\n",
    "test_accuracy(dataloaders_dict[\"test\"], model_ft_densenet, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322a3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
